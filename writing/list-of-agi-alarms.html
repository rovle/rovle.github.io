<!doctype html>
<html lang="en-us">

    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="ie=edge">
        <meta name="theme-color" content="#FE5185">
        <meta name="msapplication-TileColor" content="#FE5185">

        <meta itemprop="name" content="List" of AGI Fire Alarms · Lovre Pesut>
        <meta itemprop="description" content="Things" which caused me to update on closeness of AGI.>

        
        <meta property="og:title" content="List" of AGI Fire Alarms · Lovre Pesut />
        <meta property="og:description" content="Things" which caused me to update on closeness of AGI. />
        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary" />
        <meta name="twitter:title" content="List" of AGI Fire Alarms · Lovre Pesut />
        <meta name="twitter:description" content="Things" which caused me to update on closeness of AGI. />

        <link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
        <link rel="manifest" href="../site.webmanifest">
        <link rel="mask-icon" href="../safari-pinned-tab.svg" color>
        <link rel="shortcut icon" href="../favicon.ico">

        <title>List of AGI Fire Alarms · Lovre Pesut</title>

        <link rel="stylesheet" href="../css/style.css">
        <link href="https://lovrepesut.com/fancybox.css" rel="stylesheet">
        <link href="../css/footnotes.css" rel="stylesheet">
        <link href="../css/horizontal_ruler.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans|Unica+One&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://use.typekit.net/ssc3wax.css">
        <link href="https://fonts.googleapis.com/css2?family=Old+Standard+TT&display=swap" rel="stylesheet">
    </head>

    <body id="page">

        <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>

<script type="text/javascript" src="../js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js"></script>

  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="../" class="logo"></a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
    </div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="../">
        <li class="mobile-menu-item">Home</li>
      </a>
      <a href="../writing/alignment">
          <li class="mobile-menu-item">Alignment</li>
        </a>
        <a href="../writing/">
            <li class="mobile-menu-item">Writing</li>
        </a>
      <a href="../contact">
        <li class="mobile-menu-item">Contact</li>
      </a>
  </ul>
</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="../" class="logo"></a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="../">Home</a>
      </li>
      <li class="menu-item">
        <a class="menu-item-link" href="../writing/alignment">Alignment</a>
      </li>
        <li class="menu-item">
        <a class="menu-item-link" href="../writing/">Writing</a>
      </li>
      <li class="menu-item">
        <a class="menu-item-link" href="../contact">Contact</a>
      </li>
  </ul>
</nav>

    </header>

    	<main class="site-main section-inner thin animated fadeIn faster">
		<div class="content">
            <p><em>This is an unabridged version of this list, which contains a lot of my commentary. If you would just like to read the list with minimal commentary, you can take a look at the <a href="linkic%20na%20abridged">abridged version</a></em></p>
<p><em>Last updated: March 2022</em></p>
<p>I <a href="my%20alignment%20page">sometimes act</a> like AI becoming incredibly powerful is an event which can conceivably happen in the foreseeable future. Such a statement surely needs some substantiation, given that the rest of the world merrily turns as if such an event merits no place either in their long-term plans nor in their daily thoughts.<label for="sn-1" class="margin-toggle sidenote-number"> </label> <input type="checkbox" id="sn-1" class="margin-toggle" /> <span class="sidenote">Well, not exactly <em>the whole</em> of the rest of the world. There are rare enclaves in which such ideas are seriously considered. But it is, probably, not so in the vast majority of environments you’ve had the (mis)fortune to spectate or participate in.</span> This page is not so much a full substantiation, but rather a list of things heavily used in my underlying models; here I’ll list out advancements in AI which, roughly, seem to me more like the kinds of things which you would see some not-so-great number a years before the advent of <em>artificial general intelligence</em> (AGI)<label for="sn-2" class="margin-toggle sidenote-number"> </label> <input type="checkbox" id="sn-2" class="margin-toggle" /> <span class="sidenote">The AGI concept should not be taken as something about which I have strong definitional predispositions. You can think of it as just “sufficiently advanced AI”, sufficiently advanced that turning it on without deeply understanding it might be unprecedently dangerous, say.</span>, rather than say 100 or 200 years before – AGI fire alarms, if you will. I will mostly be focusing on big events, impresive models, but of course, it is not just big events which make me update my view of the future; “little things” are, howeve, somewhat harder to explicate – also, much harder to write compellingly about.</p>
<p>#—</p>
<p>To know when a bucket is due to overfill, you need to know three things: the shape of bucket, the amount of substance in it so far, and the rate the substance is getting poured in. This post is primarily about the <em>amount</em> in the bucket – about what has happened in the field of AI so far. But some thoughts and considerations about shape and rate are also necessary to properly contextualize why the amount is actually significant, and I’ll try to shed some limited light to those as well.</p>
<p>But the reader should be forewarned – or foresoothed – that this post is not meant to “convince” them, for to “convince”, one would indeed have to speak much more about the shape and the rate – and though it might fortuitously occur that reader’s view of those things coincidences with mine, and hence what I write here will be sufficient for our two views to converge, that is not meant to be the default outcome. This post is here to merely inform you of the results of the last 10 years of rapid advancements in machine learning, give you a bit of my contextualization why it is important, so you can rethink it for yourself, to conclude whether it really <em>is</em> important. But, as such, it should be noted that <em>if you’ve been ardently following ML developments in the last ~10 years, this post is likely to offer little to you</em>. It is, rather, geared to those who might wish to have had followed more.</p>
<p>#—</p>
<p>But in order to tell the story of the last few years, it makes sense to first spend just a few words exploring what had happened <em>before</em> those few years.</p>
<h1 id="short-story-of-a-long-period-1951---2012">Short story of a long period (1951 - 2012)</h1>
<p>[guy, maybe Samuel Johnson] writes on how eventually “machines” might become evolving themselves to raeach supremacy — a distant dream is born — Erewohn, maybe … Alan Turing, in 151, writes “a heretical theory”, in which he quite honestly considers the possibility of machine becoming superior and so on… I. J Good notes the intelligence explosion, but does not stress <em>just</em> the extinction but also that… A force is beginning to be ensmbled. at Darthmouth… by now, the force counts some … in the next years, that number will grow … and the amount of compute being spent on this search will rise 10 billion [track this down]</p>
<h2 id="the-past-future-2012--">The past future (2012 - )</h2>
<h1 id="alexnet-2012">AlexNet (2012)</h1>
<p>While neural nets had been around for many decades, the real breakthrough came when researchers realized they could use GPUs (graphical processing units, the workhorses of graphical cards in everyday PCs) in order to train NNs much faster than before. These techniques started being developed in 2006., continued heavily in the beginning 2010s, but the first major achievement of that method was AlexNet, a 60-million parameter neural network which won the ImageNet classification challenge in 2012. It was as if this event had awoken some ancient spirits, and the rest of the history of the Imagenet challenge can be easily summarized with a single graph<label for="sn-3" class="margin-toggle sidenote-number"> </label> <input type="checkbox" id="sn-3" class="margin-toggle" /> <span class="sidenote">2010 and 2011 were non-neural net models, 2012 and beyond were all NNs.</span></p>
<p>https://www.researchgate.net/publication/350195581/figure/fig1/AS:1022178313113607@1620717709806/Error-rates-of-the-winning-entries-on-the-ImageNet-Large-Scale-Visual-Recognition.jpg (source https://www.researchgate.net/figure/Error-rates-of-the-winning-entries-on-the-ImageNet-Large-Scale-Visual-Recognition_fig1_350195581 )</p>
<h1 id="solving-image-generation-2014">Solving image generation (~2014)</h1>
<p>It was shown, by AlexNet and later, that NNs can <em>classify</em> images. Question is also whether models can learn the distribution of images enough to <em>generate</em> images of a certain class.<label for="sn-4" class="margin-toggle sidenote-number"> </label> <input type="checkbox" id="sn-4" class="margin-toggle" /> <span class="sidenote">If you’re technically inclined, you can think of the first problem as learning the conditional distribution of a class given a picture, and the second the conditional distribution of a picture given a class.</span></p>
<p>GANs were used to classify faces, and progress was rapid:</p>
<p>https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-the-Progression-in-the-Capabilities-of-GANs-from-2014-to-2017.png</p>
<p>But have in recent years used to generate a plethora of “nonexistent” things, spawning a plethora of “this{x}doesnotexist.com” websites. You can see a bunch of them here:</p>
<p>https://thisxdoesnotexist.com/</p>
<h1 id="solving-simple-video-games-2013---2020">Solving simple video games (2013 - 2020)</h1>
<p>Game-playing was a staple of AI efforts since its very inception, but one quite lacking aspect of it, especially pertaining to video games, was that AI programs usually took in as input some kind of simplified input – sanitized list of moves say – instead of the actuallly “seeing” a game the way humans do. That’s why in DeepMind launched a big-scale effort to create agents which would master the old Atari games just by looking at the pixels on the screen.</p>
<p>One of the first fruits of their labor was DQN, 2014 agent which could learn some of the simpler Atari games to an arguably superhuman level; see <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">this video</a> for a short demonstration; and those efforts culminating in 2020 with <a href="https://www.deepmind.com/blog/agent57-outperforming-the-human-atari-benchmark">Agent57</a>, an agent which managed to obtain a score above human baseline on all 57 Atari games see DM’s <a href="https://assets-global.website-files.com/621e749a546b7592125f38ed/62274eaa75887b03a74748ef_Fig%203.svg">infographics for progress from DQN to Agent57</a>.</p>
<h1 id="solving-combinatorial-explosion-prone-board-games-2016-2018">Solving combinatorial-explosion-prone board games (2016-2018)</h1>
<p>But the really really big event in game-playing happened in 2016. The game of go had been, for many decades, heralded as something almost untouchable by AI. For simple reason for why this is so, and especially why it is so for Go and not for chess, consider that in Chess you have roughly 30 move possibilities each turn, while in go you have about 250. And then, as you have to plan multiple moves ahead, note how e.g. both 30^5 and 250^5 are big numbers, the latter is about 40 times greater than the former. Hence go is subject to the so-called combinatorial explosions, whereby just searching through move branches very quickly becomes infeasible: you need <em>intuition</em>. (Also, as opposed to chess, in go there is no clear way to measure material advantage, i.e. there isn’t a raeadily available metric such as “how many enemy pieces have I captured”)</p>
<p>[look at what Eliezer said about AlphaGo in those dialogues]</p>
<p>And, finally, in 2016, AI gained intuition. Okay, not really, but researchers at DeepMind found ways to train neural networks to search the possible move branches in somewhat resembling “intuition”.</p>
<p>AlphaGo, while it learned most of the things by playing itself, started its training by lookinga at a loot of human matches. Later on AlphaZero was developed, which looked at <em>zero</em> human play, and proceeded to become even much better than AlphaGo, while also showing that it was surpassing the best chess-playing programs …</p>
<h1 id="interlude-transformers---maybe-not-have-this-nor-the-other-interlude">Interlude: Transformers &lt;- maybe not have this? nor the other interlude?</h1>
<h1 id="and-then-there-was-natural-language-2019-2022">And then there was natural language (2019-2022)</h1>
<p>GPT-2</p>
<p>Natural language processing had been one of the focuses on AI ever since its very inceptions, the ELIZA chatbot being perhaps one of the first AI programs ever made. https://en.wikipedia.org/wiki/ELIZA And yet, through a succession of more and more capable bots, there was always something missing. Always it was just either canned responses or almost totally incoherent, or…</p>
<p>Then came the era of training really large models on really large amounts of text data. And, it is beginning to look suspiciously like that might indeed be enough. (Gwern’s <a href="https://www.gwern.net/Scaling-hypothesis">The Scaling Hypothesis</a> is a really, really good piece about this.</p>
<p>Then GPT-2 came, trained a on a large amount of internet text, and showed some beginning signs of coherence. I shan’t talk too much about GPT-2, because GPT-3 is almost the same thing as GPT-2 only bigger and “better”, so I shall immediately talk about it.</p>
<p>I met an atheist once who said to me That he was going to start believing In the Great Australian God of the forests And the plains and the Blue Mountains and the sea, And I said to him: “What do you want with a god Who leaves the trees that drop their leaves in autumn To wave the next year green, and the clouds that pass And the wind that blows over the woman you love, And the quokkas that stand up on their hind legs And the platypuses and the kangaroos? What do you want with a God who gives you All the creatures under the sun And leaves you to choose a right and wrong When the quokkas hug and the kangaroos kiss?</p>
<p>Mention gopher</p>
<h1 id="ai-writing-code-2021">AI writing code (2021)</h1>
<p>The same architecture as GPT-3, the same model basically, but only finetuned on code, showed that it can write code to a large degree of accuracy. https://www.youtube.com/watch?v=Zm9B-DvwOgw https://andrewmayneblog.wordpress.com/2022/03/17/building-games-and-apps-entirely-through-natural-language-using-openais-davinci-code-model/</p>
<h1 id="protein-solving-2021">Protein solving? (2021)</h1>
<p>Nearly every process in our bodies, from … to …, is modulated by proteins which have “folded” into certain shapes, and thus folded they perform certain function. It has been a long-standing challenge of science, one of its greatest ones in the last 50 years, to understand how to go from a list of amino acids which make up a protein, to <a href="https://cdn.rcsb.org/images/structures/o2/4o2x/4o2x_chain-A.jpeg">its 3D structure</a>.</p>
<p>First protein structure discovery happened in 1957, after 22 years of work on it; about 50 years later, the total number of protein structures was roughly 24 thousand. Some 20 years more later than that, an AI system figured out the structure of xxx proteins within a few months of computations.</p>
<h1 id="dall-e-2021-glide-2022">DALL-E (2021), GLIDE (2022)</h1>
<h1 id="interlude-ii-the-blessings-of-scale">Interlude II: The blessings of scale</h1>
<h1 id="honourable-mentions">Honourable mentions</h1>
<ul>
<li>https://openai.com/blog/jukebox/</li>
<li>2 IMO problems</li>
<li>https://deepmind.com/blog/article/capture-the-flag-science (video ovdje)</li>
<li>OpenAI Five / AlphaStar. The reason why these are only honourable mentions is because – while I didn’t really pay <em>that</em> close of an attention of them, it seemed to me that they do have some slightly “unfair” advantages compared to humans, so I decided to wait whether these works are going to have some deeper sequalae. And I think they have not, really, yet?</li>
<li>Language translation - anecdote about Google Translate</li>
</ul>
<h1 id="epilogue">Epilogue:</h1>
<p>“Of course, one could probaly compile a similar list of promising treatments for cancer, a sleuth of incredibly impressive-sounding in-vitro studies, which might makr guide one to the (probably false) conclusion that the”cure for cancer” is just around the corner. Only, things on this page are not in-vitro – I’ve purposefully, for the most part, excluded systems which are not actually tested, which are not making some practical difference. These systems are winning prestigious breakthrough awards and beating world champions in Go and folding proteins and demomstrating incredibly fast acquisiton of skilss and …”</p>
<p>Eventually I hope to write something about my explicit models of cognition, if for not other reason, than to clarify them for myself through writing.</p>
<p>As a closing word, I should note that this post is not meant as a subversion of an article whose names inspired this post’s name – Yudkowsky’s splending <a href="https://intelligence.org/2017/10/13/fire-alarm/">There’s No Fire Alarm for Artificial General Intelligence</a>. As Yudkowsky writes in the article, with which I largely agree</p>
<p>[QUOTE]There is never going to be a time before the end when you can look around nervously, and see that it is now clearly common knowledge that you can talk about AGI being imminent, and take action and exit the building in an orderly fashion, without fear of looking stupid or frightened.[/QUOTE]</p>
<p>If this is true, well… even if we can’t change the wider socio-epistemic landscape, perhaps <em>we</em>, the people not afraid of looking stupid or frightened, can talk among each other and try to improve our views; even if so few in the wider world will listen, we do have our <em>narrow</em> world, and sometimes, just sometimes, it takes only a fellowship to save the world.</p>

		</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p></p>  

  <script src="../jquery.min.js"></script>
  <script src="../slideout.min.js"></script>
  <script src="../fancybox.js"></script>



<script type="text/javascript" src="../auxiliary.js"></script>



</body>

</html>
